{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630b71e8",
   "metadata": {},
   "source": [
    "# 🎯 Clean Google Maps Review Scraper\n",
    "\n",
    "**Completely redesigned approach focusing on individual reviewers**\n",
    "\n",
    "This scraper properly extracts:\n",
    "- 📝 **Reviewer Name**: Individual person who wrote the review\n",
    "- ⭐ **Star Rating**: Stars given by that specific reviewer\n",
    "- 💬 **Review Text**: The actual review content\n",
    "- 🏢 **Business/Apartment Name**: Location being reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "a73cc19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "📚 All libraries imported successfully!\n",
      "🎯 Ready to scrape Google Maps reviews with precision!\n"
     ]
    }
   ],
   "source": [
    "# 📚 Import Required Libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "print(\"📚 All libraries imported successfully!\")\n",
    "print(\"🎯 Ready to scrape Google Maps reviews with precision!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "d87fa73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔧 Driver setup function ready\n"
     ]
    }
   ],
   "source": [
    "def setup_driver(headless=False):\n",
    "    \"\"\"\n",
    "    Setup Chrome driver with optimal settings for Google Maps\n",
    "    \"\"\"\n",
    "    try:\n",
    "        options = Options()\n",
    "        \n",
    "        # Anti-detection settings\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option('useAutomationExtension', False)\n",
    "        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "        \n",
    "        if headless:\n",
    "            options.add_argument('--headless')\n",
    "        \n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        driver.maximize_window()\n",
    "        \n",
    "        # Remove webdriver property\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        \n",
    "        print(\"✅ Chrome driver setup complete\")\n",
    "        return driver\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Driver setup failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"🔧 Driver setup function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "a2611f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🏢 Business name, navigation, and review expansion functions ready\n"
     ]
    }
   ],
   "source": [
    "def get_business_name(driver):\n",
    "    \"\"\"\n",
    "    Extract the business/apartment name from Google Maps\n",
    "    \"\"\"\n",
    "    name_selectors = [\n",
    "        \"h1[data-attrid='title']\",\n",
    "        \"h1.DUwDvf\",\n",
    "        \"h1.fontHeadlineLarge\", \n",
    "        \"div.lMbq3e h1\",\n",
    "        \"h1\"\n",
    "    ]\n",
    "    \n",
    "    for selector in name_selectors:\n",
    "        try:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "            name = element.text.strip()\n",
    "            if name and len(name) > 2:\n",
    "                print(f\"🏢 Found business: {name}\")\n",
    "                return name\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return \"Unknown Business\"\n",
    "\n",
    "def navigate_to_reviews(driver):\n",
    "    \"\"\"\n",
    "    Navigate to the reviews tab in Google Maps\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        \n",
    "        # Look for Reviews button/tab\n",
    "        review_selectors = [\n",
    "            \"button[data-value='Reviews']\",\n",
    "            \"[data-tab-index='1']\",\n",
    "            \"button[aria-label*='Reviews']\",\n",
    "            \"div[role='tab'][aria-label*='Reviews']\"\n",
    "        ]\n",
    "        \n",
    "        for selector in review_selectors:\n",
    "            try:\n",
    "                reviews_tab = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
    "                reviews_tab.click()\n",
    "                print(\"📝 Clicked on Reviews tab\")\n",
    "                time.sleep(3)\n",
    "                return True\n",
    "            except TimeoutException:\n",
    "                continue\n",
    "        \n",
    "        print(\"ℹ️ Already on reviews or reviews visible\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Navigation issue: {e}\")\n",
    "        return True  # Continue anyway\n",
    "\n",
    "def expand_all_reviews(driver):\n",
    "    \"\"\"\n",
    "    Find and click all \"More\" buttons to expand truncated reviews\n",
    "    \"\"\"\n",
    "    print(\"🔍 Looking for 'More' buttons to expand reviews...\")\n",
    "    \n",
    "    # Different selectors for \"More\" buttons\n",
    "    more_button_selectors = [\n",
    "        \"button[aria-label*='More']\",\n",
    "        \"button[data-expandable-section]\",\n",
    "        \"//button[contains(text(), 'More')]\",\n",
    "        \"//button[contains(@aria-label, 'more')]\",\n",
    "        \".review-more-link\",\n",
    "        \"button.review-more-button\"\n",
    "    ]\n",
    "    \n",
    "    expanded_count = 0\n",
    "    \n",
    "    for selector in more_button_selectors:\n",
    "        try:\n",
    "            if selector.startswith(\"//\"):  # XPath selector\n",
    "                more_buttons = driver.find_elements(By.XPATH, selector)\n",
    "            else:  # CSS selector\n",
    "                more_buttons = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            \n",
    "            for button in more_buttons:\n",
    "                try:\n",
    "                    if button.is_displayed() and button.is_enabled():\n",
    "                        # Scroll button into view\n",
    "                        driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", button)\n",
    "                        time.sleep(1)\n",
    "                        \n",
    "                        # Click the button\n",
    "                        button.click()\n",
    "                        expanded_count += 1\n",
    "                        time.sleep(1)  # Wait for expansion\n",
    "                        \n",
    "                except Exception as e:\n",
    "                    continue\n",
    "                    \n",
    "        except Exception as e:\n",
    "            continue\n",
    "    \n",
    "    if expanded_count > 0:\n",
    "        print(f\"✅ Expanded {expanded_count} 'More' buttons\")\n",
    "    else:\n",
    "        print(\"ℹ️ No 'More' buttons found or they were already expanded\")\n",
    "    \n",
    "    return expanded_count\n",
    "\n",
    "print(\"🏢 Business name, navigation, and review expansion functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "4a17a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "👤 Individual reviewer extraction function ready\n"
     ]
    }
   ],
   "source": [
    "def extract_reviewer_data(review_element):\n",
    "    \"\"\"\n",
    "    Extract individual reviewer's name, stars, and review text\n",
    "    IMPROVED: Better targeting of individual review components\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reviewer_data = {\n",
    "            'reviewer_name': 'Unknown',\n",
    "            'stars': 'N/A', \n",
    "            'review_text': 'No text available'\n",
    "        }\n",
    "        \n",
    "        # 1. Extract REVIEWER NAME - More specific targeting\n",
    "        name_selectors = [\n",
    "            \".d4r55\",  # Primary reviewer name class\n",
    "            \"a .d4r55\",  # Name within link\n",
    "            \".TSUbDb .d4r55\",\n",
    "            \".fontHeaderMedium\",\n",
    "            \"[aria-label] .d4r55\"\n",
    "        ]\n",
    "        \n",
    "        reviewer_name_found = False\n",
    "        for selector in name_selectors:\n",
    "            try:\n",
    "                name_elements = review_element.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for name_elem in name_elements:\n",
    "                    name = name_elem.text.strip()\n",
    "                    if name and len(name) > 1 and len(name) < 100:  # Reasonable name length\n",
    "                        reviewer_data['reviewer_name'] = name\n",
    "                        reviewer_name_found = True\n",
    "                        break\n",
    "                if reviewer_name_found:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 2. Extract STAR RATING - Look for star images/aria-labels\n",
    "        star_selectors = [\n",
    "            \"span[role='img'][aria-label*='star']\",\n",
    "            \"div[role='img'][aria-label*='star']\", \n",
    "            \"[aria-label*='stars'][role='img']\",\n",
    "            \"[aria-label*='Rated'][role='img']\",\n",
    "            \".kvMYJc[role='img']\"\n",
    "        ]\n",
    "        \n",
    "        stars_found = False\n",
    "        for selector in star_selectors:\n",
    "            try:\n",
    "                star_elements = review_element.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for star_elem in star_elements:\n",
    "                    aria_label = star_elem.get_attribute('aria-label')\n",
    "                    if aria_label and ('star' in aria_label.lower() or 'rated' in aria_label.lower()):\n",
    "                        # Extract rating from labels like \"Rated 5 out of 5 stars\" or \"4 stars\"\n",
    "                        rating_match = re.search(r'(\\d+(?:\\.\\d+)?)', aria_label)\n",
    "                        if rating_match:\n",
    "                            rating = rating_match.group(1)\n",
    "                            if 1 <= float(rating) <= 5:  # Valid star rating\n",
    "                                reviewer_data['stars'] = rating\n",
    "                                stars_found = True\n",
    "                                break\n",
    "                if stars_found:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 3. Extract REVIEW TEXT - Look for actual review content\n",
    "        # First, try to click \"More\" button to expand full review text\n",
    "        try:\n",
    "            more_buttons = review_element.find_elements(By.CSS_SELECTOR, \"button[aria-label*='More']\")\n",
    "            if not more_buttons:\n",
    "                more_buttons = review_element.find_elements(By.XPATH, \".//button[contains(text(), 'More')]\")\n",
    "            if not more_buttons:\n",
    "                more_buttons = review_element.find_elements(By.CSS_SELECTOR, \"[data-expandable-section] button\")\n",
    "            \n",
    "            for more_button in more_buttons:\n",
    "                try:\n",
    "                    if more_button.is_displayed() and more_button.is_enabled():\n",
    "                        more_button.click()\n",
    "                        time.sleep(1)  # Wait for text to expand\n",
    "                        print(\"   🔍 Clicked 'More' to expand review\")\n",
    "                        break\n",
    "                except:\n",
    "                    continue\n",
    "        except:\n",
    "            pass  # Continue if no \"More\" button found\n",
    "        \n",
    "        text_selectors = [\n",
    "            \".wiI7pd\",  # Main review text\n",
    "            \".MyEned .wiI7pd\",\n",
    "            \"span.wiI7pd\",\n",
    "            \"[data-expandable-section] .wiI7pd\",\n",
    "            \"[data-expandable-section] span\",\n",
    "            \".review-text\",\n",
    "            \".fontBodyMedium span\"\n",
    "        ]\n",
    "        \n",
    "        review_text_found = False\n",
    "        for selector in text_selectors:\n",
    "            try:\n",
    "                text_elements = review_element.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for text_elem in text_elements:\n",
    "                    text = text_elem.text.strip()\n",
    "                    # More strict filtering for actual review content\n",
    "                    if (text and len(text) > 20 and len(text) < 3000 and  # Reasonable length (increased for full text)\n",
    "                        text != reviewer_data['reviewer_name'] and  # Not the name\n",
    "                        'star' not in text.lower() and  # Not rating text\n",
    "                        'rated' not in text.lower() and  # Not rating text\n",
    "                        not text.isdigit() and  # Not just numbers\n",
    "                        not re.match(r'^[\\d\\s\\.,]+$', text)):  # Not just numbers/dates\n",
    "                        reviewer_data['review_text'] = text[:1000]  # Increased limit for full reviews\n",
    "                        review_text_found = True\n",
    "                        break\n",
    "                if review_text_found:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Only return data if we found at least name and either stars or text\n",
    "        if (reviewer_data['reviewer_name'] != 'Unknown' and \n",
    "            (reviewer_data['stars'] != 'N/A' or reviewer_data['review_text'] != 'No text available')):\n",
    "            return reviewer_data\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"⚠️ Error extracting reviewer data: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"👤 Individual reviewer extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "048767ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🔍 Main scraping function ready\n"
     ]
    }
   ],
   "source": [
    "def scrape_reviews(driver, max_reviews):\n",
    "    \"\"\"\n",
    "    Main function to scrape individual reviews from Google Maps\n",
    "    ENHANCED: Now handles \"More\" buttons and better scrolling for more reviews\n",
    "    \"\"\"\n",
    "    reviews = []\n",
    "    seen_reviewers = set()  # Track unique reviewers to avoid duplicates\n",
    "    \n",
    "    print(f\"🎯 Starting to scrape {max_reviews} UNIQUE individual reviews...\")\n",
    "    \n",
    "    # Wait for reviews to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Enhanced scrolling to load more reviews\n",
    "    print(\"📜 Scrolling to load more reviews...\")\n",
    "    for scroll_attempt in range(10):  # More scroll attempts for larger review counts\n",
    "        # Scroll down\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "        \n",
    "        # Also try scrolling the reviews container specifically\n",
    "        try:\n",
    "            reviews_container = driver.find_element(By.CSS_SELECTOR, \".m6QErb\")\n",
    "            driver.execute_script(\"arguments[0].scrollTop = arguments[0].scrollHeight;\", reviews_container)\n",
    "        except:\n",
    "            pass\n",
    "        \n",
    "        # Check if we have enough review containers\n",
    "        containers = driver.find_elements(By.CSS_SELECTOR, \"div[data-review-id]\")\n",
    "        print(f\"   📦 Scroll {scroll_attempt + 1}: Found {len(containers)} review containers\")\n",
    "        \n",
    "        if len(containers) >= max_reviews + 5:  # Get a few extra to account for filtering\n",
    "            break\n",
    "        \n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Find review containers - try most specific first\n",
    "    container_selectors = [\n",
    "        \"div[data-review-id]\",  # Most reliable - actual review containers\n",
    "        \"div.jftiEf\",  # Individual review blocks\n",
    "        \"div.MyEned\",  # Alternative review container\n",
    "    ]\n",
    "    \n",
    "    review_containers = []\n",
    "    for selector in container_selectors:\n",
    "        try:\n",
    "            containers = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if containers and len(containers) > 1:  # Need multiple containers for multiple reviews\n",
    "                review_containers = containers\n",
    "                print(f\"📦 Found {len(containers)} review containers using: {selector}\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not review_containers:\n",
    "        print(\"❌ No review containers found\")\n",
    "        return []\n",
    "    \n",
    "    # Extract data from each unique review container\n",
    "    count = 0\n",
    "    processed_containers = 0\n",
    "    \n",
    "    for container in review_containers:\n",
    "        if count >= max_reviews:\n",
    "            break\n",
    "            \n",
    "        processed_containers += 1\n",
    "        print(f\"\\n🔍 Processing container {processed_containers}/{len(review_containers)}\")\n",
    "            \n",
    "        try:\n",
    "            # Scroll container into view for better extraction\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", container)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Extract reviewer data (this now includes \"More\" button handling)\n",
    "            reviewer_data = extract_reviewer_data(container)\n",
    "            \n",
    "            if reviewer_data and reviewer_data['reviewer_name'] != 'Unknown':\n",
    "                reviewer_name = reviewer_data['reviewer_name']\n",
    "                \n",
    "                # Check if we've already seen this reviewer (avoid duplicates)\n",
    "                if reviewer_name not in seen_reviewers:\n",
    "                    seen_reviewers.add(reviewer_name)\n",
    "                    reviews.append(reviewer_data)\n",
    "                    count += 1\n",
    "                    print(f\"✅ UNIQUE Review {count}: {reviewer_name} | {reviewer_data['stars']}⭐\")\n",
    "                    print(f\"   📝 Text: {reviewer_data['review_text'][:80]}...\")\n",
    "                else:\n",
    "                    print(f\"⚠️ Skipping duplicate reviewer: {reviewer_name}\")\n",
    "            else:\n",
    "                print(\"⚠️ Could not extract valid reviewer data from this container\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"❌ Error processing container: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\n🎉 Successfully extracted {len(reviews)} UNIQUE reviews from {processed_containers} containers\")\n",
    "    return reviews\n",
    "\n",
    "print(\"🔍 Main scraping function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "cd668e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "💾 CSV saving function ready\n"
     ]
    }
   ],
   "source": [
    "def save_to_csv(reviews, business_name):\n",
    "    \"\"\"\n",
    "    Save the extracted reviews to a CSV file\n",
    "    \"\"\"\n",
    "    if not reviews:\n",
    "        print(\"❌ No reviews to save\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Add business name to each review\n",
    "        for review in reviews:\n",
    "            review['business_name'] = business_name\n",
    "        \n",
    "        # Create DataFrame with proper column order\n",
    "        df = pd.DataFrame(reviews)\n",
    "        columns = ['business_name', 'reviewer_name', 'stars', 'review_text']\n",
    "        df = df[columns]\n",
    "        \n",
    "        # Generate filename\n",
    "        safe_name = business_name.replace(' ', '_').replace('/', '_')\n",
    "        filename = f\"clean_reviews_{safe_name}.csv\"\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"💾 Saved {len(reviews)} reviews to {filename}\")\n",
    "        print(\"\\n📊 Sample data:\")\n",
    "        print(df.to_string(max_colwidth=60, index=False))\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"❌ Error saving CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"💾 CSV saving function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "7152675c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🚀 Main scraper function ready to use!\n"
     ]
    }
   ],
   "source": [
    "def run_clean_scraper(url, max_reviews=2000, headless=False):\n",
    "    \"\"\"\n",
    "    🚀 MAIN FUNCTION - Clean Google Maps Review Scraper\n",
    "    \n",
    "    This function orchestrates the entire scraping process:\n",
    "    1. Sets up the browser\n",
    "    2. Navigates to the URL  \n",
    "    3. Gets the business name\n",
    "    4. Navigates to reviews\n",
    "    5. Extracts individual reviewer data\n",
    "    6. Saves to CSV\n",
    "    \"\"\"\n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        print(\"🎯 CLEAN GOOGLE MAPS REVIEW SCRAPER\")\n",
    "        print(\"=\" * 45)\n",
    "        \n",
    "        # Step 1: Setup driver\n",
    "        print(\"🔧 Setting up Chrome driver...\")\n",
    "        driver = setup_driver(headless=headless)\n",
    "        if not driver:\n",
    "            return False\n",
    "        \n",
    "        # Step 2: Navigate to URL\n",
    "        print(f\"🌐 Loading: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Step 3: Get business name\n",
    "        business_name = get_business_name(driver)\n",
    "        \n",
    "        # Step 4: Navigate to reviews\n",
    "        print(\"📝 Navigating to reviews section...\")\n",
    "        navigate_to_reviews(driver)\n",
    "        \n",
    "        # Step 4.5: Expand all \"More\" buttons to get full review text\n",
    "        print(\"🔍 Expanding all reviews...\")\n",
    "        expand_all_reviews(driver)\n",
    "        \n",
    "        # Step 5: Extract reviews\n",
    "        reviews = scrape_reviews(driver, max_reviews=max_reviews)\n",
    "        \n",
    "        if reviews:\n",
    "            # Step 6: Save to CSV\n",
    "            save_to_csv(reviews, business_name)\n",
    "            \n",
    "            print(\"\\n🎉 SCRAPING COMPLETED SUCCESSFULLY!\")\n",
    "            print(f\"🏢 Business: {business_name}\")\n",
    "            print(f\"📊 Reviews extracted: {len(reviews)}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\n❌ No reviews were extracted\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\n❌ Scraping failed: {e}\")\n",
    "        return False\n",
    "        \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            print(\"\\n✅ Browser closed\")\n",
    "\n",
    "print(\"🚀 Main scraper function ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "c964672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "🎯 EXECUTING CLEAN SCRAPER - FIXED VERSION\n",
      "🔧 Now properly extracts UNIQUE individual reviewers\n",
      "📍 URL: https://maps.app.goo.gl/wT5sboiYx8TDCUgX7\n",
      "📊 Max Reviews: 5\n",
      "---------------------------------------------\n",
      "🎯 CLEAN GOOGLE MAPS REVIEW SCRAPER\n",
      "=============================================\n",
      "🔧 Setting up Chrome driver...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "✅ Chrome driver setup complete\n",
      "🌐 Loading: https://maps.app.goo.gl/wT5sboiYx8TDCUgX7\n",
      "🏢 Found business: The Holly\n",
      "📝 Navigating to reviews section...\n",
      "📝 Clicked on Reviews tab\n",
      "🔍 Expanding all reviews...\n",
      "🔍 Looking for 'More' buttons to expand reviews...\n",
      "✅ Expanded 11 'More' buttons\n",
      "🎯 Starting to scrape 5 UNIQUE individual reviews...\n",
      "📜 Scrolling to load more reviews...\n",
      "   📦 Scroll 1: Found 40 review containers\n",
      "📦 Found 40 review containers using: div[data-review-id]\n",
      "\n",
      "🔍 Processing container 1/40\n",
      "✅ UNIQUE Review 1: Bibek Dhungana | 1⭐\n",
      "   📝 Text: I’m the guarantor for Apartment 627A. We have signed leases for both Summer and ...\n",
      "\n",
      "🔍 Processing container 2/40\n",
      "⚠️ Skipping duplicate reviewer: Bibek Dhungana\n",
      "\n",
      "🔍 Processing container 3/40\n",
      "✅ UNIQUE Review 2: Joshue Lewis | 5⭐\n",
      "   📝 Text: I absolutely love living at The Holly! The location is unbeatable, especially fo...\n",
      "\n",
      "🔍 Processing container 4/40\n",
      "⚠️ Skipping duplicate reviewer: Joshue Lewis\n",
      "\n",
      "🔍 Processing container 5/40\n",
      "✅ UNIQUE Review 3: Katherine Earley | 1⭐\n",
      "   📝 Text: No text available...\n",
      "\n",
      "🔍 Processing container 6/40\n",
      "⚠️ Skipping duplicate reviewer: Katherine Earley\n",
      "\n",
      "🔍 Processing container 7/40\n",
      "✅ UNIQUE Review 4: Kelcy Walling | 5⭐\n",
      "   📝 Text: The unit we moved in to was honestly okay, I see where people are having issues ...\n",
      "\n",
      "🔍 Processing container 8/40\n",
      "⚠️ Skipping duplicate reviewer: Kelcy Walling\n",
      "\n",
      "🔍 Processing container 9/40\n",
      "✅ UNIQUE Review 5: Amber Petty | 3⭐\n",
      "   📝 Text: I lived at the holly for like 6 months. It honestly wasn’t horrible, maintenance...\n",
      "\n",
      "🎉 Successfully extracted 5 UNIQUE reviews from 9 containers\n",
      "💾 Saved 5 reviews to clean_reviews_The_Holly.csv\n",
      "\n",
      "📊 Sample data:\n",
      "business_name    reviewer_name stars                                                  review_text\n",
      "    The Holly   Bibek Dhungana     1 I’m the guarantor for Apartment 627A. We have signed leas...\n",
      "    The Holly     Joshue Lewis     5 I absolutely love living at The Holly! The location is un...\n",
      "    The Holly Katherine Earley     1                                            No text available\n",
      "    The Holly    Kelcy Walling     5 The unit we moved in to was honestly okay, I see where pe...\n",
      "    The Holly      Amber Petty     3 I lived at the holly for like 6 months. It honestly wasn’...\n",
      "\n",
      "🎉 SCRAPING COMPLETED SUCCESSFULLY!\n",
      "🏢 Business: The Holly\n",
      "📊 Reviews extracted: 5\n",
      "\n",
      "✅ Browser closed\n",
      "\n",
      "✅ All done! Check your CSV file for UNIQUE reviewer results.\n"
     ]
    }
   ],
   "source": [
    "# 🎯 RUN THE CLEAN SCRAPER\n",
    "# Replace the URL with your target Google Maps location\n",
    "\n",
    "# Configuration\n",
    "TARGET_URL = \"https://maps.app.goo.gl/wT5sboiYx8TDCUgX7\"  # Replace with your URL\n",
    "MAX_REVIEWS = 5  # Start with 2 reviews for testing\n",
    "HEADLESS = False  # Set to True to hide browser\n",
    "\n",
    "print(\"🎯 EXECUTING CLEAN SCRAPER - FIXED VERSION\")\n",
    "print(\"🔧 Now properly extracts UNIQUE individual reviewers\")\n",
    "print(f\"📍 URL: {TARGET_URL}\")\n",
    "print(f\"📊 Max Reviews: {MAX_REVIEWS}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Run the scraper\n",
    "success = run_clean_scraper(\n",
    "    url=TARGET_URL,\n",
    "    max_reviews=MAX_REVIEWS, \n",
    "    headless=HEADLESS\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(\"\\n✅ All done! Check your CSV file for UNIQUE reviewer results.\")\n",
    "else:\n",
    "    print(\"\\n❌ Scraping unsuccessful. Check the URL and try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
