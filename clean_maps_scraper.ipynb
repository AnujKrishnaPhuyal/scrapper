{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "630b71e8",
   "metadata": {},
   "source": [
    "# ğŸ¯ Clean Google Maps Review Scraper\n",
    "\n",
    "**Completely redesigned approach focusing on individual reviewers**\n",
    "\n",
    "This scraper properly extracts:\n",
    "- ğŸ“ **Reviewer Name**: Individual person who wrote the review\n",
    "- â­ **Star Rating**: Stars given by that specific reviewer\n",
    "- ğŸ’¬ **Review Text**: The actual review content\n",
    "- ğŸ¢ **Business/Apartment Name**: Location being reviewed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "a73cc19f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ“š All libraries imported successfully!\n",
      "ğŸ¯ Ready to scrape Google Maps reviews with precision!\n"
     ]
    }
   ],
   "source": [
    "# ğŸ“š Import Required Libraries\n",
    "import pandas as pd\n",
    "import time\n",
    "import re\n",
    "from selenium import webdriver\n",
    "from selenium.webdriver.common.by import By\n",
    "from selenium.webdriver.support.ui import WebDriverWait\n",
    "from selenium.webdriver.support import expected_conditions as EC\n",
    "from selenium.webdriver.chrome.service import Service\n",
    "from selenium.webdriver.chrome.options import Options\n",
    "from selenium.common.exceptions import TimeoutException, NoSuchElementException\n",
    "from webdriver_manager.chrome import ChromeDriverManager\n",
    "from selenium.webdriver.common.action_chains import ActionChains\n",
    "from selenium.webdriver.common.keys import Keys\n",
    "\n",
    "print(\"ğŸ“š All libraries imported successfully!\")\n",
    "print(\"ğŸ¯ Ready to scrape Google Maps reviews with precision!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "d87fa73f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ”§ Driver setup function ready\n"
     ]
    }
   ],
   "source": [
    "def setup_driver(headless=False):\n",
    "    \"\"\"\n",
    "    Setup Chrome driver with optimal settings for Google Maps\n",
    "    \"\"\"\n",
    "    try:\n",
    "        options = Options()\n",
    "        \n",
    "        # Anti-detection settings\n",
    "        options.add_argument('--no-sandbox')\n",
    "        options.add_argument('--disable-dev-shm-usage')\n",
    "        options.add_argument('--disable-blink-features=AutomationControlled')\n",
    "        options.add_experimental_option(\"excludeSwitches\", [\"enable-automation\"])\n",
    "        options.add_experimental_option('useAutomationExtension', False)\n",
    "        options.add_argument('--user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')\n",
    "        \n",
    "        if headless:\n",
    "            options.add_argument('--headless')\n",
    "        \n",
    "        service = Service(ChromeDriverManager().install())\n",
    "        driver = webdriver.Chrome(service=service, options=options)\n",
    "        driver.maximize_window()\n",
    "        \n",
    "        # Remove webdriver property\n",
    "        driver.execute_script(\"Object.defineProperty(navigator, 'webdriver', {get: () => undefined})\")\n",
    "        \n",
    "        print(\"âœ… Chrome driver setup complete\")\n",
    "        return driver\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Driver setup failed: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"ğŸ”§ Driver setup function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "a2611f40",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¢ Business name and navigation functions ready\n"
     ]
    }
   ],
   "source": [
    "def get_business_name(driver):\n",
    "    \"\"\"\n",
    "    Extract the business/apartment name from Google Maps\n",
    "    \"\"\"\n",
    "    name_selectors = [\n",
    "        \"h1[data-attrid='title']\",\n",
    "        \"h1.DUwDvf\",\n",
    "        \"h1.fontHeadlineLarge\", \n",
    "        \"div.lMbq3e h1\",\n",
    "        \"h1\"\n",
    "    ]\n",
    "    \n",
    "    for selector in name_selectors:\n",
    "        try:\n",
    "            element = driver.find_element(By.CSS_SELECTOR, selector)\n",
    "            name = element.text.strip()\n",
    "            if name and len(name) > 2:\n",
    "                print(f\"ğŸ¢ Found business: {name}\")\n",
    "                return name\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    return \"Unknown Business\"\n",
    "\n",
    "def navigate_to_reviews(driver):\n",
    "    \"\"\"\n",
    "    Navigate to the reviews tab in Google Maps\n",
    "    \"\"\"\n",
    "    try:\n",
    "        wait = WebDriverWait(driver, 15)\n",
    "        \n",
    "        # Look for Reviews button/tab\n",
    "        review_selectors = [\n",
    "            \"button[data-value='Reviews']\",\n",
    "            \"[data-tab-index='1']\",\n",
    "            \"button[aria-label*='Reviews']\",\n",
    "            \"div[role='tab'][aria-label*='Reviews']\"\n",
    "        ]\n",
    "        \n",
    "        for selector in review_selectors:\n",
    "            try:\n",
    "                reviews_tab = wait.until(EC.element_to_be_clickable((By.CSS_SELECTOR, selector)))\n",
    "                reviews_tab.click()\n",
    "                print(\"ğŸ“ Clicked on Reviews tab\")\n",
    "                time.sleep(3)\n",
    "                return True\n",
    "            except TimeoutException:\n",
    "                continue\n",
    "        \n",
    "        print(\"â„¹ï¸ Already on reviews or reviews visible\")\n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Navigation issue: {e}\")\n",
    "        return True  # Continue anyway\n",
    "\n",
    "print(\"ğŸ¢ Business name and navigation functions ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a17a726",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ‘¤ Individual reviewer extraction function ready\n"
     ]
    }
   ],
   "source": [
    "def extract_reviewer_data(review_element):\n",
    "    \"\"\"\n",
    "    Extract individual reviewer's name, stars, and review text\n",
    "    IMPROVED: Better targeting of individual review components\n",
    "    \"\"\"\n",
    "    try:\n",
    "        reviewer_data = {\n",
    "            'reviewer_name': 'Unknown',\n",
    "            'stars': 'N/A', \n",
    "            'review_text': 'No text available'\n",
    "        }\n",
    "        \n",
    "        # 1. Extract REVIEWER NAME - More specific targeting\n",
    "        name_selectors = [\n",
    "            \".d4r55\",  # Primary reviewer name class\n",
    "            \"a .d4r55\",  # Name within link\n",
    "            \".TSUbDb .d4r55\",\n",
    "            \".fontHeaderMedium\",\n",
    "            \"[aria-label] .d4r55\"\n",
    "        ]\n",
    "        \n",
    "        reviewer_name_found = False\n",
    "        for selector in name_selectors:\n",
    "            try:\n",
    "                name_elements = review_element.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for name_elem in name_elements:\n",
    "                    name = name_elem.text.strip()\n",
    "                    if name and len(name) > 1 and len(name) < 100:  # Reasonable name length\n",
    "                        reviewer_data['reviewer_name'] = name\n",
    "                        reviewer_name_found = True\n",
    "                        break\n",
    "                if reviewer_name_found:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 2. Extract STAR RATING - Look for star images/aria-labels\n",
    "        star_selectors = [\n",
    "            \"span[role='img'][aria-label*='star']\",\n",
    "            \"div[role='img'][aria-label*='star']\", \n",
    "            \"[aria-label*='stars'][role='img']\",\n",
    "            \"[aria-label*='Rated'][role='img']\",\n",
    "            \".kvMYJc[role='img']\"\n",
    "        ]\n",
    "        \n",
    "        stars_found = False\n",
    "        for selector in star_selectors:\n",
    "            try:\n",
    "                star_elements = review_element.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for star_elem in star_elements:\n",
    "                    aria_label = star_elem.get_attribute('aria-label')\n",
    "                    if aria_label and ('star' in aria_label.lower() or 'rated' in aria_label.lower()):\n",
    "                        # Extract rating from labels like \"Rated 5 out of 5 stars\" or \"4 stars\"\n",
    "                        rating_match = re.search(r'(\\d+(?:\\.\\d+)?)', aria_label)\n",
    "                        if rating_match:\n",
    "                            rating = rating_match.group(1)\n",
    "                            if 1 <= float(rating) <= 5:  # Valid star rating\n",
    "                                reviewer_data['stars'] = rating\n",
    "                                stars_found = True\n",
    "                                break\n",
    "                if stars_found:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # 3. Extract REVIEW TEXT - Look for actual review content\n",
    "        text_selectors = [\n",
    "            \".wiI7pd\",  # Main review text\n",
    "            \".MyEned .wiI7pd\",\n",
    "            \"span.wiI7pd\",\n",
    "            \"[data-expandable-section] .wiI7pd\",\n",
    "            \".review-text\"\n",
    "        ]\n",
    "        \n",
    "        review_text_found = False\n",
    "        for selector in text_selectors:\n",
    "            try:\n",
    "                text_elements = review_element.find_elements(By.CSS_SELECTOR, selector)\n",
    "                for text_elem in text_elements:\n",
    "                    text = text_elem.text.strip()\n",
    "                    # More strict filtering for actual review content\n",
    "                    if (text and len(text) > 20 and len(text) < 2000 and  # Reasonable length\n",
    "                        text != reviewer_data['reviewer_name'] and  # Not the name\n",
    "                        'star' not in text.lower() and  # Not rating text\n",
    "                        'rated' not in text.lower() and  # Not rating text\n",
    "                        not text.isdigit() and  # Not just numbers\n",
    "                        not re.match(r'^[\\d\\s\\.,]+$', text)):  # Not just numbers/dates\n",
    "                        reviewer_data['review_text'] = text[:500]  # Limit length\n",
    "                        review_text_found = True\n",
    "                        break\n",
    "                if review_text_found:\n",
    "                    break\n",
    "            except:\n",
    "                continue\n",
    "        \n",
    "        # Only return data if we found at least name and either stars or text\n",
    "        if (reviewer_data['reviewer_name'] != 'Unknown' and \n",
    "            (reviewer_data['stars'] != 'N/A' or reviewer_data['review_text'] != 'No text available')):\n",
    "            return reviewer_data\n",
    "        else:\n",
    "            return None\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âš ï¸ Error extracting reviewer data: {e}\")\n",
    "        return None\n",
    "\n",
    "print(\"ğŸ‘¤ Individual reviewer extraction function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "048767ed",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ” Main scraping function ready\n"
     ]
    }
   ],
   "source": [
    "def scrape_reviews(driver, max_reviews):\n",
    "    \"\"\"\n",
    "    Main function to scrape individual reviews from Google Maps\n",
    "    Focus on getting exactly what we need: name, stars, review text\n",
    "    FIXED: Now properly extracts unique individual reviewers\n",
    "    \"\"\"\n",
    "    reviews = []\n",
    "    seen_reviewers = set()  # Track unique reviewers to avoid duplicates\n",
    "    \n",
    "    print(f\"ğŸ¯ Starting to scrape {max_reviews} UNIQUE individual reviews...\")\n",
    "    \n",
    "    # Wait for reviews to load\n",
    "    time.sleep(5)\n",
    "    \n",
    "    # Scroll down to load more reviews if needed\n",
    "    for scroll_attempt in range(3):\n",
    "        driver.execute_script(\"window.scrollTo(0, document.body.scrollHeight);\")\n",
    "        time.sleep(2)\n",
    "    \n",
    "    # Find review containers - try most specific first\n",
    "    container_selectors = [\n",
    "        \"div[data-review-id]\",  # Most reliable - actual review containers\n",
    "        \"div.jftiEf\",  # Individual review blocks\n",
    "        \"div.MyEned\",  # Alternative review container\n",
    "    ]\n",
    "    \n",
    "    review_containers = []\n",
    "    for selector in container_selectors:\n",
    "        try:\n",
    "            containers = driver.find_elements(By.CSS_SELECTOR, selector)\n",
    "            if containers and len(containers) > 1:  # Need multiple containers for multiple reviews\n",
    "                review_containers = containers\n",
    "                print(f\"ğŸ“¦ Found {len(containers)} review containers using: {selector}\")\n",
    "                break\n",
    "        except:\n",
    "            continue\n",
    "    \n",
    "    if not review_containers:\n",
    "        print(\"âŒ No review containers found\")\n",
    "        return []\n",
    "    \n",
    "    # Extract data from each unique review container\n",
    "    count = 0\n",
    "    processed_containers = 0\n",
    "    \n",
    "    for container in review_containers:\n",
    "        if count >= max_reviews:\n",
    "            break\n",
    "            \n",
    "        processed_containers += 1\n",
    "        print(f\"\\nğŸ” Processing container {processed_containers}/{len(review_containers)}\")\n",
    "            \n",
    "        try:\n",
    "            # Scroll container into view for better extraction\n",
    "            driver.execute_script(\"arguments[0].scrollIntoView({block: 'center'});\", container)\n",
    "            time.sleep(2)\n",
    "            \n",
    "            # Extract reviewer data\n",
    "            reviewer_data = extract_reviewer_data(container)\n",
    "            \n",
    "            if reviewer_data and reviewer_data['reviewer_name'] != 'Unknown':\n",
    "                reviewer_name = reviewer_data['reviewer_name']\n",
    "                \n",
    "                # Check if we've already seen this reviewer (avoid duplicates)\n",
    "                if reviewer_name not in seen_reviewers:\n",
    "                    seen_reviewers.add(reviewer_name)\n",
    "                    reviews.append(reviewer_data)\n",
    "                    count += 1\n",
    "                    print(f\"âœ… UNIQUE Review {count}: {reviewer_name} | {reviewer_data['stars']}â­\")\n",
    "                    print(f\"   ğŸ“ Text: {reviewer_data['review_text'][:80]}...\")\n",
    "                else:\n",
    "                    print(f\"âš ï¸ Skipping duplicate reviewer: {reviewer_name}\")\n",
    "            else:\n",
    "                print(\"âš ï¸ Could not extract valid reviewer data from this container\")\n",
    "            \n",
    "        except Exception as e:\n",
    "            print(f\"âŒ Error processing container: {e}\")\n",
    "            continue\n",
    "    \n",
    "    print(f\"\\nğŸ‰ Successfully extracted {len(reviews)} UNIQUE reviews from {processed_containers} containers\")\n",
    "    return reviews\n",
    "\n",
    "print(\"ğŸ” Main scraping function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "cd668e64",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ’¾ CSV saving function ready\n"
     ]
    }
   ],
   "source": [
    "def save_to_csv(reviews, business_name):\n",
    "    \"\"\"\n",
    "    Save the extracted reviews to a CSV file\n",
    "    \"\"\"\n",
    "    if not reviews:\n",
    "        print(\"âŒ No reviews to save\")\n",
    "        return False\n",
    "    \n",
    "    try:\n",
    "        # Add business name to each review\n",
    "        for review in reviews:\n",
    "            review['business_name'] = business_name\n",
    "        \n",
    "        # Create DataFrame with proper column order\n",
    "        df = pd.DataFrame(reviews)\n",
    "        columns = ['business_name', 'reviewer_name', 'stars', 'review_text']\n",
    "        df = df[columns]\n",
    "        \n",
    "        # Generate filename\n",
    "        safe_name = business_name.replace(' ', '_').replace('/', '_')\n",
    "        filename = f\"clean_reviews_{safe_name}.csv\"\n",
    "        \n",
    "        # Save to CSV\n",
    "        df.to_csv(filename, index=False, encoding='utf-8')\n",
    "        \n",
    "        print(f\"ğŸ’¾ Saved {len(reviews)} reviews to {filename}\")\n",
    "        print(\"\\nğŸ“Š Sample data:\")\n",
    "        print(df.to_string(max_colwidth=60, index=False))\n",
    "        \n",
    "        return True\n",
    "        \n",
    "    except Exception as e:\n",
    "        print(f\"âŒ Error saving CSV: {e}\")\n",
    "        return False\n",
    "\n",
    "print(\"ğŸ’¾ CSV saving function ready\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "7152675c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Main scraper function ready to use!\n"
     ]
    }
   ],
   "source": [
    "def run_clean_scraper(url, max_reviews=2000, headless=False):\n",
    "    \"\"\"\n",
    "    ğŸš€ MAIN FUNCTION - Clean Google Maps Review Scraper\n",
    "    \n",
    "    This function orchestrates the entire scraping process:\n",
    "    1. Sets up the browser\n",
    "    2. Navigates to the URL  \n",
    "    3. Gets the business name\n",
    "    4. Navigates to reviews\n",
    "    5. Extracts individual reviewer data\n",
    "    6. Saves to CSV\n",
    "    \"\"\"\n",
    "    driver = None\n",
    "    \n",
    "    try:\n",
    "        print(\"ğŸ¯ CLEAN GOOGLE MAPS REVIEW SCRAPER\")\n",
    "        print(\"=\" * 45)\n",
    "        \n",
    "        # Step 1: Setup driver\n",
    "        print(\"ğŸ”§ Setting up Chrome driver...\")\n",
    "        driver = setup_driver(headless=headless)\n",
    "        if not driver:\n",
    "            return False\n",
    "        \n",
    "        # Step 2: Navigate to URL\n",
    "        print(f\"ğŸŒ Loading: {url}\")\n",
    "        driver.get(url)\n",
    "        time.sleep(5)\n",
    "        \n",
    "        # Step 3: Get business name\n",
    "        business_name = get_business_name(driver)\n",
    "        \n",
    "        # Step 4: Navigate to reviews\n",
    "        print(\"ğŸ“ Navigating to reviews section...\")\n",
    "        navigate_to_reviews(driver)\n",
    "        \n",
    "        # Step 5: Extract reviews\n",
    "        reviews = scrape_reviews(driver, max_reviews=max_reviews)\n",
    "        \n",
    "        if reviews:\n",
    "            # Step 6: Save to CSV\n",
    "            save_to_csv(reviews, business_name)\n",
    "            \n",
    "            print(\"\\nğŸ‰ SCRAPING COMPLETED SUCCESSFULLY!\")\n",
    "            print(f\"ğŸ¢ Business: {business_name}\")\n",
    "            print(f\"ğŸ“Š Reviews extracted: {len(reviews)}\")\n",
    "            return True\n",
    "        else:\n",
    "            print(\"\\nâŒ No reviews were extracted\")\n",
    "            return False\n",
    "            \n",
    "    except Exception as e:\n",
    "        print(f\"\\nâŒ Scraping failed: {e}\")\n",
    "        return False\n",
    "        \n",
    "    finally:\n",
    "        if driver:\n",
    "            driver.quit()\n",
    "            print(\"\\nâœ… Browser closed\")\n",
    "\n",
    "print(\"ğŸš€ Main scraper function ready to use!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "c964672e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸ¯ EXECUTING CLEAN SCRAPER - FIXED VERSION\n",
      "ğŸ”§ Now properly extracts UNIQUE individual reviewers\n",
      "ğŸ“ URL: https://maps.app.goo.gl/wT5sboiYx8TDCUgX7\n",
      "ğŸ“Š Max Reviews: 2000\n",
      "---------------------------------------------\n",
      "ğŸ¯ CLEAN GOOGLE MAPS REVIEW SCRAPER\n",
      "=============================================\n",
      "ğŸ”§ Setting up Chrome driver...\n",
      "âœ… Chrome driver setup complete\n",
      "ğŸŒ Loading: https://maps.app.goo.gl/wT5sboiYx8TDCUgX7\n",
      "ğŸ¢ Found business: The Holly\n",
      "ğŸ“ Navigating to reviews section...\n",
      "ğŸ“ Clicked on Reviews tab\n",
      "ğŸ¯ Starting to scrape 2000 UNIQUE individual reviews...\n",
      "ğŸ“¦ Found 20 review containers using: div[data-review-id]\n",
      "\n",
      "ğŸ” Processing container 1/20\n",
      "âœ… UNIQUE Review 1: Bibek Dhungana | 1â­\n",
      "   ğŸ“ Text: Iâ€™m the guarantor for Apartment 627A. We have signed leases for both Summer and ...\n",
      "\n",
      "ğŸ” Processing container 2/20\n",
      "âš ï¸ Skipping duplicate reviewer: Bibek Dhungana\n",
      "\n",
      "ğŸ” Processing container 3/20\n",
      "âœ… UNIQUE Review 2: Joshue Lewis | 5â­\n",
      "   ğŸ“ Text: I absolutely love living at The Holly! The location is unbeatable, especially fo...\n",
      "\n",
      "ğŸ” Processing container 4/20\n",
      "âš ï¸ Skipping duplicate reviewer: Joshue Lewis\n",
      "\n",
      "ğŸ” Processing container 5/20\n",
      "âœ… UNIQUE Review 3: Katherine Earley | 1â­\n",
      "   ğŸ“ Text: Updated Review August 27th, 2025: This complex is now charging $300 to clean car...\n",
      "\n",
      "ğŸ” Processing container 6/20\n",
      "âš ï¸ Skipping duplicate reviewer: Katherine Earley\n",
      "\n",
      "ğŸ” Processing container 7/20\n",
      "âœ… UNIQUE Review 4: Kelcy Walling | 5â­\n",
      "   ğŸ“ Text: The unit we moved in to was honestly okay, I see where people are having issues ...\n",
      "\n",
      "ğŸ” Processing container 8/20\n",
      "âš ï¸ Skipping duplicate reviewer: Kelcy Walling\n",
      "\n",
      "ğŸ” Processing container 9/20\n",
      "âœ… UNIQUE Review 5: Amber Petty | 3â­\n",
      "   ğŸ“ Text: I lived at the holly for like 6 months. It honestly wasnâ€™t horrible, maintenance...\n",
      "\n",
      "ğŸ” Processing container 10/20\n",
      "âš ï¸ Skipping duplicate reviewer: Amber Petty\n",
      "\n",
      "ğŸ” Processing container 11/20\n",
      "âœ… UNIQUE Review 6: Aye'vah Cabrera | 5â­\n",
      "   ğŸ“ Text: I just moved into the holly in August and my personal experience has been just f...\n",
      "\n",
      "ğŸ” Processing container 12/20\n",
      "âš ï¸ Skipping duplicate reviewer: Aye'vah Cabrera\n",
      "\n",
      "ğŸ” Processing container 13/20\n",
      "âœ… UNIQUE Review 7: Reed Davis | 1â­\n",
      "   ğŸ“ Text: No text available...\n",
      "\n",
      "ğŸ” Processing container 14/20\n",
      "âš ï¸ Skipping duplicate reviewer: Reed Davis\n",
      "\n",
      "ğŸ” Processing container 15/20\n",
      "âœ… UNIQUE Review 8: Emi Wise | 1â­\n",
      "   ğŸ“ Text: This place is cheap, and you can tell. Maintenance requests are only ever comple...\n",
      "\n",
      "ğŸ” Processing container 16/20\n",
      "âš ï¸ Skipping duplicate reviewer: Emi Wise\n",
      "\n",
      "ğŸ” Processing container 17/20\n",
      "âœ… UNIQUE Review 9: Bella Vandenburg | 5â­\n",
      "   ğŸ“ Text: Iâ€™ve lived at the Holly for almost a year now and have signed for another! I lov...\n",
      "\n",
      "ğŸ” Processing container 18/20\n",
      "âš ï¸ Skipping duplicate reviewer: Bella Vandenburg\n",
      "\n",
      "ğŸ” Processing container 19/20\n",
      "âœ… UNIQUE Review 10: PARIKSHIT REDDY | 1â­\n",
      "   ğŸ“ Text: I had requested them for a lease for 2 a whole 2 bedroom space for me and my fri...\n",
      "\n",
      "ğŸ” Processing container 20/20\n",
      "âš ï¸ Skipping duplicate reviewer: PARIKSHIT REDDY\n",
      "\n",
      "ğŸ‰ Successfully extracted 10 UNIQUE reviews from 20 containers\n",
      "âŒ Error saving CSV: [Errno 13] Permission denied: 'clean_reviews_The_Holly.csv'\n",
      "\n",
      "ğŸ‰ SCRAPING COMPLETED SUCCESSFULLY!\n",
      "ğŸ¢ Business: The Holly\n",
      "ğŸ“Š Reviews extracted: 10\n",
      "\n",
      "âœ… Browser closed\n",
      "\n",
      "âœ… All done! Check your CSV file for UNIQUE reviewer results.\n"
     ]
    }
   ],
   "source": [
    "# ğŸ¯ RUN THE CLEAN SCRAPER\n",
    "# Replace the URL with your target Google Maps location\n",
    "\n",
    "# Configuration\n",
    "TARGET_URL = \"https://maps.app.goo.gl/wT5sboiYx8TDCUgX7\"  # Replace with your URL\n",
    "MAX_REVIEWS = 2000  # Start with 2 reviews for testing\n",
    "HEADLESS = False  # Set to True to hide browser\n",
    "\n",
    "print(\"ğŸ¯ EXECUTING CLEAN SCRAPER - FIXED VERSION\")\n",
    "print(\"ğŸ”§ Now properly extracts UNIQUE individual reviewers\")\n",
    "print(f\"ğŸ“ URL: {TARGET_URL}\")\n",
    "print(f\"ğŸ“Š Max Reviews: {MAX_REVIEWS}\")\n",
    "print(\"-\" * 45)\n",
    "\n",
    "# Run the scraper\n",
    "success = run_clean_scraper(\n",
    "    url=TARGET_URL,\n",
    "    max_reviews=MAX_REVIEWS, \n",
    "    headless=HEADLESS\n",
    ")\n",
    "\n",
    "if success:\n",
    "    print(\"\\nâœ… All done! Check your CSV file for UNIQUE reviewer results.\")\n",
    "else:\n",
    "    print(\"\\nâŒ Scraping unsuccessful. Check the URL and try again.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
